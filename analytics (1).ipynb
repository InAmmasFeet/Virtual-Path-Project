{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093b2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H&E to IF Marker Pattern Analysis\n",
      "==================================================\n",
      "This analysis will identify:\n",
      "• Spatial distribution of DAPI, CD8, and CD163 markers\n",
      "• Colocalization patterns between markers\n",
      "• Correlation with H&E morphological features\n",
      "• Regional variations in marker expression\n",
      "• Immune activity hotspots\n",
      "• Statistical relationships for model training insights\n",
      "\n",
      "================================================================================\n",
      "H&E TO IF MARKER PATTERN ANALYSIS\n",
      "================================================================================\n",
      "Loading H&E image: warped_source.tiff\n",
      "  Attempting to load warped_source.tiff...\n",
      "    Trying tifffile...\n",
      "    ❌ tifffile failed: incompatible keyframe\n",
      "    Trying PIL...\n",
      "      Multi-page TIFF detected: 10 pages\n",
      "      Resizing from (30720, 46080) to (5773, 8660) for analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✅ Loaded with PIL: (8660, 5773, 3), uint8\n",
      "Loading IF image: target.tiff\n",
      "  Attempting to load target.tiff...\n",
      "    Trying tifffile...\n",
      "    Converted from CHW to HWC format\n",
      "    ✅ Loaded with tifffile: (46080, 30720, 3), uint16\n",
      "Resizing images to match: H&E (8660, 5773) -> IF (46080, 30720)\n",
      "Images loaded successfully:\n",
      "  H&E shape: (8660, 5773, 3)\n",
      "  IF shape: (8660, 5773, 3)\n",
      "  DAPI range: 0 - 4936\n",
      "  CD8 range: 0 - 2051\n",
      "  CD163 range: 0 - 2582\n",
      "Enhancing marker contrast using (1, 99.5) percentiles...\n",
      "  DAPI: 2.0-802.0 -> 0-65535.0\n",
      "  CD8: 1.0-176.0 -> 0-65535.0\n",
      "  CD163: 1.0-134.0 -> 0-65535.0\n",
      "Creating comprehensive visualization...\n",
      "Analyzing spatial patterns using 15x15 grid...\n",
      "  Created 225 regional measurements\n",
      "  Average DAPI intensity: 6446.84\n",
      "  Average CD8 intensity: 7539.98\n",
      "  Average CD163 intensity: 2349.03\n",
      "Analyzing marker colocalization (>95th percentile)...\n",
      "  DAPI_positive_pct: 3.76%\n",
      "  CD8_positive_pct: 3.61%\n",
      "  CD163_positive_pct: 2.90%\n",
      "  CD8_CD163_overlap_pct: 0.65%\n",
      "  CD8_in_DAPI_pct: 18.82%\n",
      "  CD163_in_DAPI_pct: 15.84%\n",
      "  CD8_CD163_mutual_exclusion: 88.97%\n",
      "Visualization saved: he_if_pattern_analysis/pattern_analysis_warped_source_to_target.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "from pathlib import Path\n",
    "from skimage import exposure, filters, segmentation, measure, morphology\n",
    "from skimage.color import rgb2gray\n",
    "from scipy import ndimage\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from typing import Tuple, Dict, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class HEIFPatternAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyze spatial patterns between H&E morphology and IF marker expression.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, he_image_path: str, if_image_path: str):\n",
    "        \"\"\"\n",
    "        Initialize analyzer with H&E and IF image paths.\n",
    "        \n",
    "        Args:\n",
    "            he_image_path: Path to H&E source image\n",
    "            if_image_path: Path to IF target image (3 channels: DAPI, CD8, CD163)\n",
    "        \"\"\"\n",
    "        self.he_path = Path(he_image_path)\n",
    "        self.if_path = Path(if_image_path)\n",
    "        \n",
    "        # Load images\n",
    "        print(f\"Loading H&E image: {self.he_path.name}\")\n",
    "        self.he_image = self._load_image(he_image_path)\n",
    "        \n",
    "        print(f\"Loading IF image: {self.if_path.name}\")\n",
    "        self.if_image = self._load_image(if_image_path)\n",
    "        \n",
    "        # Ensure images are the same size\n",
    "        self._resize_to_match()\n",
    "        \n",
    "        # Extract individual marker channels\n",
    "        self.dapi_channel = self.if_image[:, :, 0]  # Channel 0: DAPI (nuclei)\n",
    "        self.cd8_channel = self.if_image[:, :, 1]   # Channel 1: CD8 (T cells)\n",
    "        self.cd163_channel = self.if_image[:, :, 2] # Channel 2: CD163 (macrophages)\n",
    "        \n",
    "        # Convert H&E to grayscale for analysis\n",
    "        self.he_gray = rgb2gray(self.he_image) if len(self.he_image.shape) == 3 else self.he_image\n",
    "        \n",
    "        print(f\"Images loaded successfully:\")\n",
    "        print(f\"  H&E shape: {self.he_image.shape}\")\n",
    "        print(f\"  IF shape: {self.if_image.shape}\")\n",
    "        print(f\"  DAPI range: {self.dapi_channel.min():.0f} - {self.dapi_channel.max():.0f}\")\n",
    "        print(f\"  CD8 range: {self.cd8_channel.min():.0f} - {self.cd8_channel.max():.0f}\")\n",
    "        print(f\"  CD163 range: {self.cd163_channel.min():.0f} - {self.cd163_channel.max():.0f}\")\n",
    "    \n",
    "    def _load_image(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"Load image with multiple fallback methods for problematic TIFFs.\"\"\"\n",
    "        filepath = str(image_path)\n",
    "        filename = Path(filepath).name\n",
    "        \n",
    "        print(f\"  Attempting to load {filename}...\")\n",
    "        \n",
    "        # Method 1: Try tifffile (best for scientific TIFFs)\n",
    "        try:\n",
    "            print(f\"    Trying tifffile...\")\n",
    "            with tifffile.TiffFile(filepath) as tif:\n",
    "                image = tif.asarray()\n",
    "                \n",
    "                # Handle different channel arrangements\n",
    "                if len(image.shape) == 3:\n",
    "                    if image.shape[0] <= 10:  # (C, H, W) format\n",
    "                        image = np.transpose(image, (1, 2, 0))  # Convert to (H, W, C)\n",
    "                        print(f\"    Converted from CHW to HWC format\")\n",
    "                \n",
    "                print(f\"    ✅ Loaded with tifffile: {image.shape}, {image.dtype}\")\n",
    "                return image\n",
    "        except Exception as e:\n",
    "            print(f\"    ❌ tifffile failed: {e}\")\n",
    "        \n",
    "        # Method 2: Try PIL with increased limits\n",
    "        try:\n",
    "            print(f\"    Trying PIL...\")\n",
    "            from PIL import Image\n",
    "            \n",
    "            # Temporarily increase PIL's size limits\n",
    "            original_max_pixels = Image.MAX_IMAGE_PIXELS\n",
    "            Image.MAX_IMAGE_PIXELS = None  # Remove limit entirely\n",
    "            \n",
    "            try:\n",
    "                with Image.open(filepath) as img:\n",
    "                    # Handle multi-page TIFFs\n",
    "                    if hasattr(img, 'n_frames') and img.n_frames > 1:\n",
    "                        print(f\"      Multi-page TIFF detected: {img.n_frames} pages\")\n",
    "                        img.seek(0)  # Go to first page\n",
    "                    \n",
    "                    # For very large images, resize to manageable size\n",
    "                    original_size = img.size\n",
    "                    total_pixels = original_size[0] * original_size[1]\n",
    "                    \n",
    "                    if total_pixels > 100_000_000:  # >100M pixels\n",
    "                        target_pixels = 50_000_000  # 50M pixels target\n",
    "                        scale_factor = (target_pixels / total_pixels) ** 0.5\n",
    "                        new_size = (int(original_size[0] * scale_factor), \n",
    "                                   int(original_size[1] * scale_factor))\n",
    "                        print(f\"      Resizing from {original_size} to {new_size} for analysis\")\n",
    "                        img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "                    \n",
    "                    image = np.array(img)\n",
    "                    print(f\"    ✅ Loaded with PIL: {image.shape}, {image.dtype}\")\n",
    "                    return image\n",
    "            finally:\n",
    "                # Restore original limit\n",
    "                Image.MAX_IMAGE_PIXELS = original_max_pixels\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    ❌ PIL failed: {e}\")\n",
    "        \n",
    "        # Method 3: Try OpenCV\n",
    "        try:\n",
    "            print(f\"    Trying OpenCV...\")\n",
    "            import cv2\n",
    "            import os\n",
    "            \n",
    "            # Override OpenCV's pixel limit\n",
    "            original_env = os.environ.get('OPENCV_IO_MAX_IMAGE_PIXELS', None)\n",
    "            os.environ['OPENCV_IO_MAX_IMAGE_PIXELS'] = str(2**31-1)\n",
    "            \n",
    "            try:\n",
    "                image = cv2.imread(filepath, cv2.IMREAD_UNCHANGED)\n",
    "                if image is not None:\n",
    "                    # OpenCV loads as BGR, convert to RGB if 3 channels\n",
    "                    if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    print(f\"    ✅ Loaded with OpenCV: {image.shape}, {image.dtype}\")\n",
    "                    return image\n",
    "                else:\n",
    "                    print(f\"    ❌ OpenCV returned None\")\n",
    "            finally:\n",
    "                # Restore original environment\n",
    "                if original_env is not None:\n",
    "                    os.environ['OPENCV_IO_MAX_IMAGE_PIXELS'] = original_env\n",
    "                else:\n",
    "                    os.environ.pop('OPENCV_IO_MAX_IMAGE_PIXELS', None)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"    ❌ OpenCV failed: {e}\")\n",
    "        \n",
    "        # Method 4: Try imageio\n",
    "        try:\n",
    "            print(f\"    Trying imageio...\")\n",
    "            import imageio.v2 as imageio\n",
    "            \n",
    "            image = imageio.imread(filepath)\n",
    "            print(f\"    ✅ Loaded with imageio: {image.shape}, {image.dtype}\")\n",
    "            return image\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    ❌ imageio failed: {e}\")\n",
    "        \n",
    "        # Method 5: Try reading specific page with tifffile\n",
    "        try:\n",
    "            print(f\"    Trying tifffile page-by-page...\")\n",
    "            with tifffile.TiffFile(filepath) as tif:\n",
    "                # Try reading individual pages\n",
    "                for page_idx in range(min(3, len(tif.pages))):\n",
    "                    try:\n",
    "                        page = tif.pages[page_idx]\n",
    "                        image = page.asarray()\n",
    "                        \n",
    "                        # Handle channel arrangements\n",
    "                        if len(image.shape) == 3 and image.shape[0] <= 10:\n",
    "                            image = np.transpose(image, (1, 2, 0))\n",
    "                        \n",
    "                        print(f\"    ✅ Loaded page {page_idx} with tifffile: {image.shape}, {image.dtype}\")\n",
    "                        return image\n",
    "                    except:\n",
    "                        continue\n",
    "        except Exception as e:\n",
    "            print(f\"    ❌ Page-by-page reading failed: {e}\")\n",
    "        \n",
    "        # All methods failed\n",
    "        print(f\"    ❌ All loading methods failed for {filename}\")\n",
    "        raise RuntimeError(f\"Could not load image {filename} with any available method\")\n",
    "    \n",
    "    def _resize_to_match(self):\n",
    "        \"\"\"Ensure both images have the same dimensions.\"\"\"\n",
    "        he_shape = self.he_image.shape[:2]\n",
    "        if_shape = self.if_image.shape[:2]\n",
    "        \n",
    "        if he_shape != if_shape:\n",
    "            print(f\"Resizing images to match: H&E {he_shape} -> IF {if_shape}\")\n",
    "            min_height = min(he_shape[0], if_shape[0])\n",
    "            min_width = min(he_shape[1], if_shape[1])\n",
    "            \n",
    "            from skimage.transform import resize\n",
    "            \n",
    "            if len(self.he_image.shape) == 3:\n",
    "                self.he_image = resize(self.he_image, (min_height, min_width, self.he_image.shape[2]), \n",
    "                                     preserve_range=True, anti_aliasing=True).astype(self.he_image.dtype)\n",
    "            else:\n",
    "                self.he_image = resize(self.he_image, (min_height, min_width), \n",
    "                                     preserve_range=True, anti_aliasing=True).astype(self.he_image.dtype)\n",
    "            \n",
    "            self.if_image = resize(self.if_image, (min_height, min_width, self.if_image.shape[2]), \n",
    "                                 preserve_range=True, anti_aliasing=True).astype(self.if_image.dtype)\n",
    "    \n",
    "    def enhance_markers(self, percentile_range=(1, 99.5)):\n",
    "        \"\"\"\n",
    "        Enhance marker visibility using percentile-based contrast stretching.\n",
    "        \n",
    "        Args:\n",
    "            percentile_range: Percentiles for contrast enhancement\n",
    "        \"\"\"\n",
    "        print(f\"Enhancing marker contrast using {percentile_range} percentiles...\")\n",
    "        \n",
    "        for i, (channel, name) in enumerate([(self.dapi_channel, 'DAPI'), \n",
    "                                           (self.cd8_channel, 'CD8'), \n",
    "                                           (self.cd163_channel, 'CD163')]):\n",
    "            if np.any(channel > 0):\n",
    "                p_low, p_high = np.percentile(channel[channel > 0], percentile_range)\n",
    "                enhanced = exposure.rescale_intensity(channel, in_range=(p_low, p_high))\n",
    "                \n",
    "                if i == 0:\n",
    "                    self.dapi_channel = enhanced\n",
    "                elif i == 1:\n",
    "                    self.cd8_channel = enhanced\n",
    "                else:\n",
    "                    self.cd163_channel = enhanced\n",
    "                \n",
    "                print(f\"  {name}: {p_low:.1f}-{p_high:.1f} -> 0-{enhanced.max():.1f}\")\n",
    "    \n",
    "    def segment_tissue_regions(self, he_threshold=0.1, min_area=1000):\n",
    "        \"\"\"\n",
    "        Segment tissue regions from background in H&E image.\n",
    "        \n",
    "        Args:\n",
    "            he_threshold: Threshold for tissue vs background\n",
    "            min_area: Minimum area for tissue regions\n",
    "        \n",
    "        Returns:\n",
    "            Binary mask of tissue regions\n",
    "        \"\"\"\n",
    "        print(\"Segmenting tissue regions...\")\n",
    "        \n",
    "        # Simple threshold-based segmentation\n",
    "        tissue_mask = self.he_gray > he_threshold\n",
    "        \n",
    "        # Remove small objects\n",
    "        tissue_mask = morphology.remove_small_objects(tissue_mask, min_size=min_area)\n",
    "        \n",
    "        # Fill holes\n",
    "        tissue_mask = ndimage.binary_fill_holes(tissue_mask)\n",
    "        \n",
    "        tissue_percentage = np.sum(tissue_mask) / tissue_mask.size * 100\n",
    "        print(f\"  Tissue coverage: {tissue_percentage:.1f}%\")\n",
    "        \n",
    "        return tissue_mask\n",
    "    \n",
    "    def analyze_marker_colocalization(self, threshold_percentile=95):\n",
    "        \"\"\"\n",
    "        Analyze spatial relationships between different markers.\n",
    "        \n",
    "        Args:\n",
    "            threshold_percentile: Percentile threshold for positive staining\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with colocalization statistics\n",
    "        \"\"\"\n",
    "        print(f\"Analyzing marker colocalization (>{threshold_percentile}th percentile)...\")\n",
    "        \n",
    "        # Define positive staining thresholds\n",
    "        dapi_thresh = np.percentile(self.dapi_channel[self.dapi_channel > 0], threshold_percentile)\n",
    "        cd8_thresh = np.percentile(self.cd8_channel[self.cd8_channel > 0], threshold_percentile)\n",
    "        cd163_thresh = np.percentile(self.cd163_channel[self.cd163_channel > 0], threshold_percentile)\n",
    "        \n",
    "        # Create binary masks for positive staining\n",
    "        dapi_positive = self.dapi_channel > dapi_thresh\n",
    "        cd8_positive = self.cd8_channel > cd8_thresh\n",
    "        cd163_positive = self.cd163_channel > cd163_thresh\n",
    "        \n",
    "        # Calculate colocalization\n",
    "        total_pixels = dapi_positive.size\n",
    "        \n",
    "        colocalization = {\n",
    "            'DAPI_positive_pct': np.sum(dapi_positive) / total_pixels * 100,\n",
    "            'CD8_positive_pct': np.sum(cd8_positive) / total_pixels * 100,\n",
    "            'CD163_positive_pct': np.sum(cd163_positive) / total_pixels * 100,\n",
    "            'CD8_CD163_overlap_pct': np.sum(cd8_positive & cd163_positive) / total_pixels * 100,\n",
    "            'CD8_in_DAPI_pct': np.sum(cd8_positive & dapi_positive) / np.sum(dapi_positive) * 100 if np.sum(dapi_positive) > 0 else 0,\n",
    "            'CD163_in_DAPI_pct': np.sum(cd163_positive & dapi_positive) / np.sum(dapi_positive) * 100 if np.sum(dapi_positive) > 0 else 0,\n",
    "        }\n",
    "        \n",
    "        # Mutual exclusivity analysis\n",
    "        colocalization['CD8_CD163_mutual_exclusion'] = (\n",
    "            np.sum(cd8_positive & ~cd163_positive) + np.sum(cd163_positive & ~cd8_positive)\n",
    "        ) / np.sum(cd8_positive | cd163_positive) * 100 if np.sum(cd8_positive | cd163_positive) > 0 else 0\n",
    "        \n",
    "        for key, value in colocalization.items():\n",
    "            print(f\"  {key}: {value:.2f}%\")\n",
    "        \n",
    "        return colocalization\n",
    "    \n",
    "    def analyze_spatial_patterns(self, grid_size=20):\n",
    "        \"\"\"\n",
    "        Analyze spatial patterns by dividing image into grid regions.\n",
    "        \n",
    "        Args:\n",
    "            grid_size: Number of grid divisions per side\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with regional statistics\n",
    "        \"\"\"\n",
    "        print(f\"Analyzing spatial patterns using {grid_size}x{grid_size} grid...\")\n",
    "        \n",
    "        height, width = self.he_gray.shape\n",
    "        grid_h = height // grid_size\n",
    "        grid_w = width // grid_size\n",
    "        \n",
    "        regions = []\n",
    "        \n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                # Define grid boundaries\n",
    "                y1, y2 = i * grid_h, min((i + 1) * grid_h, height)\n",
    "                x1, x2 = j * grid_w, min((j + 1) * grid_w, width)\n",
    "                \n",
    "                # Extract region data\n",
    "                he_region = self.he_gray[y1:y2, x1:x2]\n",
    "                dapi_region = self.dapi_channel[y1:y2, x1:x2]\n",
    "                cd8_region = self.cd8_channel[y1:y2, x1:x2]\n",
    "                cd163_region = self.cd163_channel[y1:y2, x1:x2]\n",
    "                \n",
    "                # Calculate regional statistics\n",
    "                region_stats = {\n",
    "                    'grid_i': i,\n",
    "                    'grid_j': j,\n",
    "                    'x_center': (x1 + x2) / 2,\n",
    "                    'y_center': (y1 + y2) / 2,\n",
    "                    'he_mean': np.mean(he_region),\n",
    "                    'he_std': np.std(he_region),\n",
    "                    'dapi_mean': np.mean(dapi_region),\n",
    "                    'dapi_max': np.max(dapi_region),\n",
    "                    'cd8_mean': np.mean(cd8_region),\n",
    "                    'cd8_max': np.max(cd8_region),\n",
    "                    'cd163_mean': np.mean(cd163_region),\n",
    "                    'cd163_max': np.max(cd163_region),\n",
    "                    'dapi_cd8_corr': np.corrcoef(dapi_region.flatten(), cd8_region.flatten())[0,1] if np.std(dapi_region) > 0 and np.std(cd8_region) > 0 else 0,\n",
    "                    'dapi_cd163_corr': np.corrcoef(dapi_region.flatten(), cd163_region.flatten())[0,1] if np.std(dapi_region) > 0 and np.std(cd163_region) > 0 else 0,\n",
    "                    'cd8_cd163_corr': np.corrcoef(cd8_region.flatten(), cd163_region.flatten())[0,1] if np.std(cd8_region) > 0 and np.std(cd163_region) > 0 else 0,\n",
    "                }\n",
    "                \n",
    "                regions.append(region_stats)\n",
    "        \n",
    "        df = pd.DataFrame(regions)\n",
    "        \n",
    "        print(f\"  Created {len(df)} regional measurements\")\n",
    "        print(f\"  Average DAPI intensity: {df['dapi_mean'].mean():.2f}\")\n",
    "        print(f\"  Average CD8 intensity: {df['cd8_mean'].mean():.2f}\")\n",
    "        print(f\"  Average CD163 intensity: {df['cd163_mean'].mean():.2f}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_comprehensive_visualization(self, save_path=None):\n",
    "        \"\"\"\n",
    "        Create comprehensive visualization of all patterns.\n",
    "        \n",
    "        Args:\n",
    "            save_path: Optional path to save the figure\n",
    "        \"\"\"\n",
    "        print(\"Creating comprehensive visualization...\")\n",
    "        \n",
    "        fig = plt.figure(figsize=(20, 16))\n",
    "        \n",
    "        # Row 1: Original images\n",
    "        plt.subplot(4, 5, 1)\n",
    "        plt.imshow(self.he_image)\n",
    "        plt.title('H&E Source Image', fontsize=12, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(4, 5, 2)\n",
    "        plt.imshow(self.dapi_channel, cmap='Blues')\n",
    "        plt.title('DAPI (Nuclei)', fontsize=12, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(4, 5, 3)\n",
    "        plt.imshow(self.cd8_channel, cmap='Reds')\n",
    "        plt.title('CD8 (T cells)', fontsize=12, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(4, 5, 4)\n",
    "        plt.imshow(self.cd163_channel, cmap='Greens')\n",
    "        plt.title('CD163 (Macrophages)', fontsize=12, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Composite IF image\n",
    "        plt.subplot(4, 5, 5)\n",
    "        # Create RGB composite\n",
    "        composite = np.zeros((*self.dapi_channel.shape, 3))\n",
    "        composite[:, :, 0] = self.cd8_channel / self.cd8_channel.max()  # Red: CD8\n",
    "        composite[:, :, 1] = self.cd163_channel / self.cd163_channel.max()  # Green: CD163\n",
    "        composite[:, :, 2] = self.dapi_channel / self.dapi_channel.max()  # Blue: DAPI\n",
    "        plt.imshow(composite)\n",
    "        plt.title('IF Composite\\n(R:CD8, G:CD163, B:DAPI)', fontsize=12, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Row 2: Overlay visualizations\n",
    "        plt.subplot(4, 5, 6)\n",
    "        plt.imshow(self.he_image)\n",
    "        plt.imshow(self.dapi_channel, alpha=0.3, cmap='Blues')\n",
    "        plt.title('H&E + DAPI Overlay', fontsize=12)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(4, 5, 7)\n",
    "        plt.imshow(self.he_image)\n",
    "        plt.imshow(self.cd8_channel, alpha=0.3, cmap='Reds')\n",
    "        plt.title('H&E + CD8 Overlay', fontsize=12)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(4, 5, 8)\n",
    "        plt.imshow(self.he_image)\n",
    "        plt.imshow(self.cd163_channel, alpha=0.3, cmap='Greens')\n",
    "        plt.title('H&E + CD163 Overlay', fontsize=12)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Colocalization maps\n",
    "        plt.subplot(4, 5, 9)\n",
    "        cd8_thresh = np.percentile(self.cd8_channel[self.cd8_channel > 0], 95)\n",
    "        cd163_thresh = np.percentile(self.cd163_channel[self.cd163_channel > 0], 95)\n",
    "        overlap = (self.cd8_channel > cd8_thresh) & (self.cd163_channel > cd163_thresh)\n",
    "        plt.imshow(overlap, cmap='hot')\n",
    "        plt.title('CD8-CD163 Colocalization', fontsize=12)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # High-intensity regions\n",
    "        plt.subplot(4, 5, 10)\n",
    "        high_activity = (self.dapi_channel > np.percentile(self.dapi_channel, 90)) | \\\n",
    "                       (self.cd8_channel > np.percentile(self.cd8_channel, 90)) | \\\n",
    "                       (self.cd163_channel > np.percentile(self.cd163_channel, 90))\n",
    "        plt.imshow(high_activity, cmap='plasma')\n",
    "        plt.title('High Activity Regions', fontsize=12)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Row 3: Spatial analysis\n",
    "        regional_df = self.analyze_spatial_patterns(grid_size=15)\n",
    "        \n",
    "        plt.subplot(4, 5, 11)\n",
    "        grid_dapi = regional_df.pivot(index='grid_i', columns='grid_j', values='dapi_mean')\n",
    "        plt.imshow(grid_dapi, cmap='Blues', aspect='auto')\n",
    "        plt.title('DAPI Spatial Distribution', fontsize=12)\n",
    "        plt.colorbar(shrink=0.8)\n",
    "        \n",
    "        plt.subplot(4, 5, 12)\n",
    "        grid_cd8 = regional_df.pivot(index='grid_i', columns='grid_j', values='cd8_mean')\n",
    "        plt.imshow(grid_cd8, cmap='Reds', aspect='auto')\n",
    "        plt.title('CD8 Spatial Distribution', fontsize=12)\n",
    "        plt.colorbar(shrink=0.8)\n",
    "        \n",
    "        plt.subplot(4, 5, 13)\n",
    "        grid_cd163 = regional_df.pivot(index='grid_i', columns='grid_j', values='cd163_mean')\n",
    "        plt.imshow(grid_cd163, cmap='Greens', aspect='auto')\n",
    "        plt.title('CD163 Spatial Distribution', fontsize=12)\n",
    "        plt.colorbar(shrink=0.8)\n",
    "        \n",
    "        # Correlation analysis\n",
    "        plt.subplot(4, 5, 14)\n",
    "        plt.scatter(regional_df['cd8_mean'], regional_df['cd163_mean'], alpha=0.6, s=20)\n",
    "        plt.xlabel('CD8 Mean Intensity')\n",
    "        plt.ylabel('CD163 Mean Intensity')\n",
    "        plt.title('CD8 vs CD163 Correlation', fontsize=12)\n",
    "        \n",
    "        correlation = np.corrcoef(regional_df['cd8_mean'], regional_df['cd163_mean'])[0,1]\n",
    "        plt.text(0.05, 0.95, f'r = {correlation:.3f}', transform=plt.gca().transAxes, \n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "        \n",
    "        # H&E texture vs markers\n",
    "        plt.subplot(4, 5, 15)\n",
    "        plt.scatter(regional_df['he_std'], regional_df['dapi_mean'], alpha=0.6, s=20, label='DAPI')\n",
    "        plt.scatter(regional_df['he_std'], regional_df['cd8_mean'], alpha=0.6, s=20, label='CD8')\n",
    "        plt.scatter(regional_df['he_std'], regional_df['cd163_mean'], alpha=0.6, s=20, label='CD163')\n",
    "        plt.xlabel('H&E Texture (std)')\n",
    "        plt.ylabel('Marker Intensity')\n",
    "        plt.title('H&E Texture vs Markers', fontsize=12)\n",
    "        plt.legend()\n",
    "        \n",
    "        # Row 4: Statistical summaries\n",
    "        plt.subplot(4, 5, 16)\n",
    "        colocalization_stats = self.analyze_marker_colocalization()\n",
    "        stats_names = ['DAPI+', 'CD8+', 'CD163+', 'CD8&CD163']\n",
    "        stats_values = [colocalization_stats['DAPI_positive_pct'], \n",
    "                       colocalization_stats['CD8_positive_pct'],\n",
    "                       colocalization_stats['CD163_positive_pct'],\n",
    "                       colocalization_stats['CD8_CD163_overlap_pct']]\n",
    "        \n",
    "        bars = plt.bar(stats_names, stats_values, color=['blue', 'red', 'green', 'purple'])\n",
    "        plt.title('Marker Positivity (%)', fontsize=12)\n",
    "        plt.ylabel('Percentage')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, stats_values):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                    f'{value:.1f}%', ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        # Intensity distributions\n",
    "        plt.subplot(4, 5, 17)\n",
    "        intensities = [self.dapi_channel.flatten(), self.cd8_channel.flatten(), self.cd163_channel.flatten()]\n",
    "        labels = ['DAPI', 'CD8', 'CD163']\n",
    "        colors = ['blue', 'red', 'green']\n",
    "        \n",
    "        for intensity, label, color in zip(intensities, labels, colors):\n",
    "            # Sample data for faster plotting\n",
    "            sample_size = min(10000, len(intensity))\n",
    "            sample_indices = np.random.choice(len(intensity), sample_size, replace=False)\n",
    "            sample_data = intensity[sample_indices]\n",
    "            plt.hist(sample_data, bins=50, alpha=0.6, label=label, color=color, density=True)\n",
    "        \n",
    "        plt.xlabel('Intensity')\n",
    "        plt.ylabel('Density')\n",
    "        plt.title('Intensity Distributions', fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.yscale('log')\n",
    "        \n",
    "        # Correlation heatmap\n",
    "        plt.subplot(4, 5, 18)\n",
    "        correlation_data = regional_df[['he_mean', 'he_std', 'dapi_mean', 'cd8_mean', 'cd163_mean']].corr()\n",
    "        im = plt.imshow(correlation_data, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "        plt.colorbar(im, shrink=0.8)\n",
    "        plt.title('Regional Correlations', fontsize=12)\n",
    "        \n",
    "        labels = ['H&E Mean', 'H&E Std', 'DAPI', 'CD8', 'CD163']\n",
    "        plt.xticks(range(len(labels)), labels, rotation=45)\n",
    "        plt.yticks(range(len(labels)), labels)\n",
    "        \n",
    "        # Add correlation values\n",
    "        for i in range(len(labels)):\n",
    "            for j in range(len(labels)):\n",
    "                plt.text(j, i, f'{correlation_data.iloc[i,j]:.2f}', \n",
    "                        ha='center', va='center', fontsize=10)\n",
    "        \n",
    "        # Spatial hotspots\n",
    "        plt.subplot(4, 5, 19)\n",
    "        # Identify hotspots (top 10% of combined marker activity)\n",
    "        combined_activity = self.dapi_channel + self.cd8_channel + self.cd163_channel\n",
    "        hotspot_thresh = np.percentile(combined_activity, 90)\n",
    "        hotspots = combined_activity > hotspot_thresh\n",
    "        \n",
    "        plt.imshow(self.he_image)\n",
    "        plt.imshow(hotspots, alpha=0.5, cmap='hot')\n",
    "        plt.title('Immune Activity Hotspots\\n(Top 10%)', fontsize=12)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Summary statistics text\n",
    "        plt.subplot(4, 5, 20)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        summary_text = f\"\"\"\n",
    "PATTERN SUMMARY\n",
    "\n",
    "Marker Coverage:\n",
    "• DAPI: {colocalization_stats['DAPI_positive_pct']:.1f}%\n",
    "• CD8: {colocalization_stats['CD8_positive_pct']:.1f}%  \n",
    "• CD163: {colocalization_stats['CD163_positive_pct']:.1f}%\n",
    "\n",
    "Colocalization:\n",
    "• CD8-CD163 overlap: {colocalization_stats['CD8_CD163_overlap_pct']:.1f}%\n",
    "• Mutual exclusion: {colocalization_stats['CD8_CD163_mutual_exclusion']:.1f}%\n",
    "\n",
    "Spatial Patterns:\n",
    "• CD8-CD163 correlation: {correlation:.3f}\n",
    "• High activity regions: {np.sum(hotspots)/hotspots.size*100:.1f}%\n",
    "\n",
    "Image Properties:\n",
    "• H&E shape: {self.he_image.shape}\n",
    "• IF shape: {self.if_image.shape}\n",
    "        \"\"\"\n",
    "        \n",
    "        plt.text(0.05, 0.95, summary_text, transform=plt.gca().transAxes, \n",
    "                fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8))\n",
    "        \n",
    "        plt.suptitle(f'H&E to IF Marker Pattern Analysis\\n{self.he_path.name} → {self.if_path.name}', \n",
    "                    fontsize=16, fontweight='bold', y=0.98)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "            print(f\"Visualization saved: {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return regional_df, colocalization_stats\n",
    "\n",
    "def analyze_he_if_patterns(he_image_path: str, if_image_path: str, output_dir: str = \"pattern_analysis\"):\n",
    "    \"\"\"\n",
    "    Complete analysis workflow for H&E to IF marker patterns.\n",
    "    \n",
    "    Args:\n",
    "        he_image_path: Path to H&E source image\n",
    "        if_image_path: Path to IF target image\n",
    "        output_dir: Directory to save results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"H&E TO IF MARKER PATTERN ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create output directory\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = HEIFPatternAnalyzer(he_image_path, if_image_path)\n",
    "    \n",
    "    # Enhance marker visibility\n",
    "    analyzer.enhance_markers()\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    save_path = output_path / f\"pattern_analysis_{analyzer.he_path.stem}_to_{analyzer.if_path.stem}.png\"\n",
    "    regional_df, colocalization_stats = analyzer.create_comprehensive_visualization(save_path=save_path)\n",
    "    \n",
    "    # Save detailed statistics\n",
    "    stats_path = output_path / f\"regional_statistics_{analyzer.he_path.stem}_to_{analyzer.if_path.stem}.csv\"\n",
    "    regional_df.to_csv(stats_path, index=False)\n",
    "    print(f\"Regional statistics saved: {stats_path}\")\n",
    "    \n",
    "    # Save colocalization results\n",
    "    coloc_path = output_path / f\"colocalization_stats_{analyzer.he_path.stem}_to_{analyzer.if_path.stem}.txt\"\n",
    "    with open(coloc_path, 'w') as f:\n",
    "        f.write(\"COLOCALIZATION STATISTICS\\n\")\n",
    "        f.write(\"=\"*40 + \"\\n\\n\")\n",
    "        for key, value in colocalization_stats.items():\n",
    "            f.write(f\"{key}: {value:.3f}%\\n\")\n",
    "    \n",
    "    print(f\"Colocalization statistics saved: {coloc_path}\")\n",
    "    \n",
    "    return analyzer, regional_df, colocalization_stats\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Update these paths to your actual image files\n",
    "    he_image_path = \"RegWSI_Pass1/Pair6/warped_source.tiff\"  # H&E source image\n",
    "    if_image_path = \"RegWSI_Pass1/Pair6/target.tiff\"         # IF target image with 3 channels\n",
    "    \n",
    "    print(\"H&E to IF Marker Pattern Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"This analysis will identify:\")\n",
    "    print(\"• Spatial distribution of DAPI, CD8, and CD163 markers\")\n",
    "    print(\"• Colocalization patterns between markers\")\n",
    "    print(\"• Correlation with H&E morphological features\")\n",
    "    print(\"• Regional variations in marker expression\")\n",
    "    print(\"• Immune activity hotspots\")\n",
    "    print(\"• Statistical relationships for model training insights\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        analyzer, regional_df, coloc_stats = analyze_he_if_patterns(\n",
    "            he_image_path=he_image_path,\n",
    "            if_image_path=if_image_path,\n",
    "            output_dir=\"he_if_pattern_analysis\"\n",
    "        )\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ANALYSIS COMPLETE!\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"Key findings:\")\n",
    "        print(f\"• DAPI coverage: {coloc_stats['DAPI_positive_pct']:.1f}% (nuclei density)\")\n",
    "        print(f\"• CD8+ T cells: {coloc_stats['CD8_positive_pct']:.1f}% (cytotoxic immune response)\")\n",
    "        print(f\"• CD163+ macrophages: {coloc_stats['CD163_positive_pct']:.1f}% (tumor-associated macrophages)\")\n",
    "        print(f\"• CD8-CD163 overlap: {coloc_stats['CD8_CD163_overlap_pct']:.1f}% (immune interaction zones)\")\n",
    "        \n",
    "        correlation = np.corrcoef(regional_df['cd8_mean'], regional_df['cd163_mean'])[0,1]\n",
    "        if correlation > 0.3:\n",
    "            print(f\"• Strong positive correlation (r={correlation:.3f}) suggests coordinated immune response\")\n",
    "        elif correlation < -0.3:\n",
    "            print(f\"• Strong negative correlation (r={correlation:.3f}) suggests competitive/exclusive patterns\")\n",
    "        else:\n",
    "            print(f\"• Weak correlation (r={correlation:.3f}) suggests independent marker patterns\")\n",
    "        \n",
    "        print(\"\\nFiles generated:\")\n",
    "        print(\"• Comprehensive visualization (PNG)\")\n",
    "        print(\"• Regional statistics (CSV)\")\n",
    "        print(\"• Colocalization summary (TXT)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Analysis failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"INTERPRETATION GUIDE\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"DAPI (Blue): Nuclear stain - indicates cell density\")\n",
    "    print(\"CD8 (Red): Cytotoxic T lymphocytes - anti-tumor immune cells\")\n",
    "    print(\"CD163 (Green): M2 macrophages - often tumor-promoting\")\n",
    "    print(\"\\nPattern Insights for Model Training:\")\n",
    "    print(\"• High DAPI + High CD8 = Active immune response regions\")\n",
    "    print(\"• High CD163 + Low CD8 = Immunosuppressive regions\")\n",
    "    print(\"• CD8-CD163 overlap = Immune interaction zones\")\n",
    "    print(\"• Spatial clustering = Organized immune structures\")\n",
    "    print(\"• H&E texture correlation = Morphology-function relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc439b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
